{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df7eddf1",
   "metadata": {},
   "source": [
    "# Spectralgen Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53142cc",
   "metadata": {},
   "source": [
    "Code related to the work \"J.J. García-Esteban, J.C. Cuevas, J. Bravo-Abad, \"Generative adversarial networks for data-scarce spectral applications in the physical sciences”, submitted for publication (2023).\"\n",
    "\n",
    "Contains:\n",
    "\n",
    "- code used to create and train the networks described. \n",
    "\n",
    "- code used to create some of the graphs in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea4a37",
   "metadata": {},
   "source": [
    "## General imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c7b95",
   "metadata": {},
   "source": [
    "Run this code to import the relevant libraries, load and prepare the datasets and define the evaluation metrics used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47290eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi']=300 # highres display\n",
    "plt.rcParams[\"figure.figsize\"] = (20,15)\n",
    "matplotlib.rcParams.update({'font.size': 30})\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "\n",
    "# Total amount of data: 6561 examples\n",
    "\n",
    "label_path = '/Users/usuario/Desktop/GAN_multilayered/labels8metal.csv'\n",
    "data_path = '/Users/usuario/Desktop/GAN_multilayered/data8metal.csv'\n",
    "\n",
    "dataindex_raw = np.genfromtxt(label_path,dtype=\"float32\") # RAW indices\n",
    "dataindex = dataindex_raw[:,[1,2,3,4,5,6,7,8]]\n",
    "datafile = np.genfromtxt(data_path,dtype=\"float32\") # RAW spectra\n",
    "\n",
    "# Random_index\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "random_index = np.linspace(0,dataindex.shape[0]-1,dataindex.shape[0])\n",
    "np.random.shuffle(random_index)\n",
    "      \n",
    "# Normalization\n",
    "\n",
    "input_mean = np.mean(np.log10(dataindex),axis=0)\n",
    "input_std = np.std(np.log10(dataindex),axis=0)\n",
    "\n",
    "data_mean = np.mean(np.log10(datafile),axis=0)\n",
    "data_std = np.std(np.log10(datafile),axis=0)\n",
    "\n",
    "# Preallocate the sets\n",
    "\n",
    "# Target data\n",
    "\n",
    "y_target = np.zeros([datafile.shape[0],datafile.shape[1]]) \n",
    "y_target_rand = np.zeros([datafile.shape[0],datafile.shape[1]])\n",
    "\n",
    "# Input data\n",
    "\n",
    "y_in = np.zeros([dataindex.shape[0],dataindex.shape[1]])\n",
    "y_in_rand = np.zeros([dataindex.shape[0],dataindex.shape[1]])\n",
    "\n",
    "# Populate the sets\n",
    "\n",
    "for i in range(dataindex.shape[0]):\n",
    "\n",
    "    index = int(random_index[i])\n",
    "    \n",
    "    y_in[i,:] = (np.log10(dataindex[i,:])-input_mean)/input_std\n",
    "    y_target[i,:] = (np.log10(datafile[i,:])-data_mean)/data_std\n",
    "    \n",
    "    y_in_rand[i,:] = (np.log10(dataindex[index,:])-input_mean)/input_std\n",
    "    y_target_rand[i,:] = (np.log10(datafile[index,:])-data_mean)/data_std\n",
    "\n",
    "# Create the train and val sets\n",
    "\n",
    "val = 0.2 # Validation fraction [0,1]\n",
    "\n",
    "train_index = np.linspace(0,np.int((1-val)*datafile.shape[0]-1),np.int((1-val)*datafile.shape[0])).astype(int)\n",
    "val_index = np.linspace(np.int((1-val)*datafile.shape[0]),datafile.shape[0]-1,np.int(val*datafile.shape[0])+1).astype(int)\n",
    "\n",
    "y_in_train = y_in_rand[train_index,:]\n",
    "y_in_val = y_in_rand[val_index,:]\n",
    "\n",
    "y_target_train = y_target_rand[train_index,:]\n",
    "y_target_val = y_target_rand[val_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27439dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "\n",
    "# FFNN\n",
    "\n",
    "def mean_relative_abs_error_pointwise(net, inputs, target):\n",
    "    \n",
    "    Npoints = target.shape[1]\n",
    "    Nexamples = target.shape[0]\n",
    "    \n",
    "    error = np.zeros([1,1])\n",
    "    \n",
    "    for i in range(Nexamples):\n",
    "        \n",
    "        fake = np.reshape(net.predict_on_batch(np.reshape(inputs[i,:],(1,inputs.shape[1]))),(Npoints,))\n",
    "        \n",
    "        faked = 10**(fake*data_std+data_mean)\n",
    "        realed = 10**(target[i,:]*data_std+data_mean)\n",
    "        \n",
    "        for j in range(Npoints):\n",
    "            \n",
    "            error = error + np.abs((faked[j]-realed[j])/realed[j])\n",
    "    \n",
    "    return error/(Npoints*Nexamples)*100\n",
    "\n",
    "def integral_relative_error(net, inputs, target):\n",
    "    \n",
    "    Npoints = target.shape[1]\n",
    "    Nexamples = target.shape[0]\n",
    "    \n",
    "    error = np.zeros([1,1])\n",
    "    \n",
    "    for i in range(Nexamples):\n",
    "        \n",
    "        fake = np.reshape(net.predict_on_batch(np.reshape(inputs[i,:],(1,inputs.shape[1]))),(Npoints,))\n",
    "        \n",
    "        faked = 10**(fake*data_std+data_mean)\n",
    "        realed = 10**(target[i,:]*data_std+data_mean)\n",
    "        \n",
    "        error = error + np.abs((np.trapz(faked)-np.trapz(realed))/np.trapz(realed))\n",
    "        \n",
    "    return error/Nexamples*100\n",
    "\n",
    "# GAN, CGAN, CWGAN\n",
    "\n",
    "def mean_relative_abs_error_pointwise_gan(net, inputs, target):\n",
    "    \n",
    "    Npoints = target.shape[1]\n",
    "    Nexamples = target.shape[0]\n",
    "    \n",
    "    error = np.zeros([1,1])\n",
    "\n",
    "    fake = net([inputs]).numpy()\n",
    "    \n",
    "    for i in range(Nexamples):\n",
    "        \n",
    "        faked = 10**(fake[i,:]*data_std+data_mean)\n",
    "        realed = 10**(target[i,:]*data_std+data_mean)\n",
    "        \n",
    "        for j in range(Npoints):\n",
    "            \n",
    "            error = error + np.abs((faked[j]-realed[j])/realed[j])\n",
    "    \n",
    "    return error/(Npoints*Nexamples)*100\n",
    "\n",
    "def integral_relative_error_gan(net, inputs, target):\n",
    "    \n",
    "    Npoints = target.shape[1]\n",
    "    Nexamples = target.shape[0]\n",
    "    \n",
    "    error = np.zeros([1,1])\n",
    "    \n",
    "    fake = net([inputs]).numpy()\n",
    "    \n",
    "    for i in range(Nexamples):\n",
    "        \n",
    "        faked = 10**(fake[i,:]*data_std+data_mean)\n",
    "        realed = 10**(target[i,:]*data_std+data_mean)\n",
    "                \n",
    "        error = error + np.abs((np.trapz(faked)-np.trapz(realed))/np.trapz(realed))\n",
    "        \n",
    "    return error/Nexamples*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb1bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
